{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Biophysics code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.00000000e+04   1.00000000e+04   1.00000000e+01   1.00000000e+04\n",
      "   1.00000000e+01   2.50000000e-08   5.00000000e-10]\n",
      "[2083 1959 1978 2002 2001 2070 2012 2056 2014 2041]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/asohanmath/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:161: DeprecationWarning: object of type <class 'float'> cannot be safely interpreted as an integer.\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# Imports\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from ccg import correlograms\n",
    "\n",
    "def compthta(Rtemp,Ttemp,delta):\n",
    "    Sobs = len(np.intersect1d(Rtemp,Ttemp))\n",
    "    mxSpk = np.max(np.append(Rtemp,Ttemp))\n",
    "    bEdges = np.arange(0,mxSpk,delta)\n",
    "    bo = histc(Rtemp, bEdges) \n",
    "    refCounts = np.append(bo[0],0)\n",
    "    w = np.floor(Ttemp/delta)\n",
    "    w = w[w!=np.max(w)]\n",
    "    Nr = refCounts[w.astype('int')]\n",
    "    Nr = Nr[Nr!=0]/delta\n",
    "    naive = Sobs - np.sum(Nr)\n",
    "    thtahat = naive/(1-((1/len(Nr))*np.sum(Nr)))\n",
    "    return thtahat\n",
    "\n",
    "def histc(X, bins):\n",
    "    map_to_bins = np.digitize(X,bins)\n",
    "    r = np.zeros(bins.shape)\n",
    "    for i in map_to_bins:\n",
    "        r[i-1] += 1\n",
    "    return [r, map_to_bins]\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Load spike data\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "train_ref = np.load('train_ref_static.npy')     # Collection of reference spike trains\n",
    "train_targ = np.load('train_targ_static.npy')   # Collection of target spike trains\n",
    "train_ref0 = np.load('train_ref0_static.npy')   # Collection of reference spike trains (no synapse)\n",
    "train_targ0 = np.load('train_targ0_static.npy') # Collection of target spike trains (no synapse)\n",
    "params = np.load('parameters.npy')\n",
    "weight_value = np.load('weights.npy')\n",
    "Ntrial = params[0]                              # Number of trials\n",
    "duration = params[1]                            # Trial duration in (ms)\n",
    "period = params[2]                              # Nonstationarity timescale in (ms)\n",
    "Fs = params[3]\n",
    "Nphase = params[4]\n",
    "phase = duration/Nphase\n",
    "gm = params[5]\n",
    "g0 = params[6]\n",
    "\n",
    "print(params)\n",
    "\n",
    "train = np.append(train_ref,train_targ)\n",
    "cell = np.int64(np.append(np.zeros(len(train_ref)),np.ones(len(train_targ))))\n",
    "\n",
    "#------------------------------------------------------------------------------\n",
    "# Analyze spike data\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "# Measure the distribution of synchrony count before injection\n",
    "synch_width = 1.*5\n",
    "#--WITH SYNAPSE--\n",
    "Tref = synch_width*np.floor(train_ref/synch_width)\n",
    "lmax = 0.#lag[np.argmax(Craw[0,1])]\n",
    "x = (train_targ-lmax)*(np.sign(train_targ-lmax)+1)/2.\n",
    "x = x[np.nonzero(x)]\n",
    "Ttarg = synch_width*np.floor(train_targ/synch_width)\n",
    "Tsynch = np.array(list(set(Tref) & set(Ttarg)))\n",
    "synch_count = np.bincount(np.int64(np.floor(Tsynch/(Ntrial*phase))),minlength=Nphase.astype('int'))\n",
    "#--WITHOUT SYNAPSE--\n",
    "Tref0 = synch_width*np.floor(train_ref0/synch_width)\n",
    "lmax0 = 0.#lag[np.argmax(Craw0[0,1])]\n",
    "x = (train_targ0-lmax0)*(np.sign(train_targ0-lmax0)+1)/2.\n",
    "x = x[np.nonzero(x)]\n",
    "Ttarg0 = synch_width*np.floor(x/synch_width)\n",
    "Tsynch0 = np.array(list(set(Tref0) & set(Ttarg0)))\n",
    "synch_count0 = np.bincount(np.int64(np.floor(Tsynch0/(Ntrial*phase))),minlength=Nphase.astype('int'))\n",
    "\n",
    "# Check the optimal synchrony window \n",
    "#Nsynch = 100 \n",
    "#synch_width_range = np.linspace(.1,10,Nsynch)\n",
    "#s = np.zeros(Nsynch)\n",
    "#s0 = np.zeros(Nsynch)\n",
    "#lmax = 0.#lag[np.argmax(Craw[0,1])]\n",
    "##print(latency/ms,lmax)\n",
    "#lmax0 = 0.#lag[np.argmax(Craw0[0,1])]\n",
    "#for k in range(Nsynch):\n",
    "#    synch_width = synch_width_range[k]\n",
    "#    #--WITH SYNAPSE--\n",
    "#    Tref = synch_width*np.floor(train_ref/synch_width)\n",
    "#    x = (train_targ-lmax)*(np.sign(train_targ-lmax)+1)/2.\n",
    "#    x = x[np.nonzero(x)]\n",
    "#    Ttarg = synch_width*np.floor(x/synch_width)\n",
    "#    Tsynch = np.array(list(set(Tref) & set(Ttarg)))\n",
    "#    synch_count = np.bincount(np.int64(np.floor(Tsynch/(Ntrial*phase))),minlength=Nphase)\n",
    "#    s[k] = np.mean(synch_count)\n",
    "#    #--WITHOUT SYNAPSE--\n",
    "#    Tref0 = synch_width*np.floor(train_ref0/synch_width)\n",
    "#    x = (train_targ0-lmax0)*(np.sign(train_targ0-lmax0)+1)/2.\n",
    "#    x = x[np.nonzero(x)]\n",
    "#    Ttarg0 = synch_width*np.floor(x/synch_width)\n",
    "#    Tsynch0 = np.array(list(set(Tref0) & set(Ttarg0)))\n",
    "#    synch_count0 = np.bincount(np.int64(np.floor(Tsynch0/(Ntrial*phase))),minlength=Nphase)\n",
    "#    s0[k] = np.mean(synch_count0)\n",
    "#plt.figure()\n",
    "##plt.plot(synch_width_range,(np.amax(Craw[0,1])-np.amax(Craw0[0,1]))*np.ones(Nsynch),'--r')\n",
    "#plt.plot(synch_width_range,s-s0,'--k')\n",
    "#plt.figure()\n",
    "##plt.plot(synch_width_range,np.amax(Craw[0,1])*np.ones(Nsynch),'--r')\n",
    "##plt.plot(synch_width_range,np.amax(Craw0[0,1])*np.ones(Nsynch),'--g')\n",
    "#plt.plot(synch_width_range,s,'o-k')\n",
    "#plt.plot(synch_width_range,s0,'o-c')\n",
    "#plt.show()    \n",
    "#exit()\n",
    "\n",
    "#print(synch_count,synch_count0)\n",
    "#print(synch_count-synch_count0)\n",
    "\n",
    "# Excess synchrony count unbiased estimation\n",
    "delta = period\n",
    "Ndelta = int(Ntrial*duration/delta)\n",
    "count_ref = np.bincount(np.int64(np.floor(train_ref/delta)),minlength=Ndelta)\n",
    "count_targ = np.bincount(np.int64(np.floor(train_targ/delta)),minlength=Ndelta)\n",
    "count_synch = np.bincount(np.int64(np.floor(Tsynch/delta)),minlength=Ndelta)\n",
    "Ndelta_phase = int(Ntrial*phase/delta)\n",
    "RS_prod = np.sum(np.reshape(count_ref*count_synch,(Nphase.astype('int'),Ndelta_phase)),axis=1)\n",
    "alpha = RS_prod/(delta*synch_count)  \n",
    "RT_prod = np.sum(np.reshape(count_ref*count_targ,(Nphase.astype('int'),Ndelta_phase)),axis=1)\n",
    "#alphaN = alpha[~np.isnan(alpha)]\n",
    "#synch_countN = synch_count[~np.isnan(alpha)]\n",
    "#RT_prodN = RT_prod[~np.isnan(alpha)]\n",
    "\n",
    "# ==================Zach revisions =======================\n",
    "#estimate = (delta*synch_count-RT_prod)/(delta*synch_count-RS_prod)*synch_count\n",
    "estimate = []; synchOn = []\n",
    "indT = np.digitize(train_targ%duration,np.arange(0,12000,1000)) - 1\n",
    "indR = np.digitize(train_ref%duration,np.arange(0,12000,1000)) - 1\n",
    "for k in range(int(len(np.unique(indT)))):\n",
    "    temp = compthta(np.round(train_ref[indR==k]),np.round(train_targ[indT==k]),delta)\n",
    "    estimate = np.append(estimate,temp)\n",
    "    temp = len(np.intersect1d(np.round(train_ref[indR==k]),np.round(train_targ[indT==k])))\n",
    "    synchOn = np.append(synchOn,temp)\n",
    "# ==================Zach revisions =======================\n",
    "\n",
    "synchOff = []\n",
    "indT = np.digitize(train_targ0%duration,np.arange(0,12000,1000)) - 1\n",
    "indR = np.digitize(train_ref0%duration,np.arange(0,12000,1000)) - 1\n",
    "for k in range(int(len(np.unique(indT)))):\n",
    "    temp = len(np.intersect1d(np.round(train_ref0[indR==k]),np.round(train_targ0[indT==k])))\n",
    "    synchOff = np.append(synchOff,temp)\n",
    "\n",
    "    \n",
    "\n",
    "# Evaluate the true injected synchrony count by comparing conditions \"synapse on\" and \"synapse off\"\n",
    "injected_true = (synch_count-synch_count0)#*1./synch_count\n",
    "print(injected_true)\n",
    "\n",
    "# Check the result\n",
    "x = synchOn-synchOff\n",
    "y = estimate\n",
    "P = np.polyfit(x, y, 1)\n",
    "xx = np.linspace(np.min(x),np.max(x),1e3)\n",
    "yy = P[0]*xx + P[1]\n",
    "\n",
    "FigEst = plt.figure(figsize=(7,5))\n",
    "colG = np.array([128,129,132])/255\n",
    "plt.plot(xx,yy,color=colG,linestyle='--')\n",
    "plt.plot(synchOn-synchOff,estimate,'ok',color='k',markersize=12)\n",
    "plt.xlabel('theta')\n",
    "plt.ylabel('theta hat')\n",
    "plt.box('off')\n",
    "\n",
    "FigCon = plt.figure(figsize=(7,5))\n",
    "y = g0*weight_value*(0-(-50))/120.*10**9\n",
    "plt.plot(y,estimate,color='k',linewidth=.7)\n",
    "plt.plot(y,estimate,'ok',color='k',markersize=12)\n",
    "plt.xlabel('Normalized peak conductance')\n",
    "plt.ylabel('theta hat')\n",
    "plt.box('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
